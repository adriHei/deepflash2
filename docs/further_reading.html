---

title: Further Reading:


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/further_reading.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/further_reading.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Technical-Terms">Technical Terms<a class="anchor-link" href="#Technical-Terms"> </a></h2><p>Preparation of training Data:
The following terms are often used, when describing the preparation work that needs to be done to generate training data that can be used to train the neural network.</p>
<h3 id="Image-segmentation">Image segmentation<a class="anchor-link" href="#Image-segmentation"> </a></h3><p>The image segmentation describes the process when a person manually marks an image. This is also called annotation. For this, instance labels are used and regions of interest can be identified.</p>
<p><a href="https://www.tensorflow.org/tutorials/images/segmentation">read more</a></p>
<h3 id="Instance-labels">Instance labels<a class="anchor-link" href="#Instance-labels"> </a></h3><p>The labels are manually set in the segmentation phase. They are used by experts to highlight the objects of interest and separate them from background noise. Often two colours are used. One for the objects which the later model should find, and one for the background or structures that should be ignored in the training process.</p>
<p><a href="https://towardsdatascience.com/image-data-labelling-and-annotation-everything-you-need-to-know-86ede6c684b1">read more</a></p>
<h3 id="ROI---Regions-of-Interest">ROI - Regions of Interest<a class="anchor-link" href="#ROI---Regions-of-Interest"> </a></h3><p>These are the regions on the image that contain the features that are most important for the training of the model. These will be manually highlighted by experts (segmented) before the training is started.</p>
<p><a href="https://towardsdatascience.com/understanding-region-of-interest-part-1-roi-pooling-e4f5dd65bb44">read more</a></p>
<h3 id="(Segmentation)-mask">(Segmentation) mask<a class="anchor-link" href="#(Segmentation)-mask"> </a></h3><p>The segmentation mask describes an image fully annotated by a person, oftentimes an expert in the corresponding field.</p>
<p><a href="https://towardsdatascience.com/generating-image-segmentation-masks-the-easy-way-dd4d3656dbd1">read more</a></p>
<h3 id="Classes">Classes<a class="anchor-link" href="#Classes"> </a></h3><p>The classes in deepFlash2 denote how many different categories of labels were used by the experts during the segmentation of the training data.</p>
<h3 id="Training-of-the-neural-network">Training of the neural network<a class="anchor-link" href="#Training-of-the-neural-network"> </a></h3><h3 id="Loss-function">Loss function<a class="anchor-link" href="#Loss-function"> </a></h3><p>The loss function determines how our neural network optimizes its precision when learning from sample data.
It defines how to determine the weights of the individual neurons.</p>
<p><a href="https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23">read more</a></p>
<h3 id="Hyperparameter">Hyperparameter<a class="anchor-link" href="#Hyperparameter"> </a></h3><p>Hyperparameters are values that we can set before the actual learning process is performed. With these parameters we can influence the duration and accuracy of the learning process.</p>
<p>Parameters are:<br>
The learning rate<br>
Number of epochs<br>
batch size</p>
<h3 id="Learning-rate">Learning rate<a class="anchor-link" href="#Learning-rate"> </a></h3><p>With the learning rate we can control the progress of the neural network when looking for an optimum. 
When adjusting the learning rate we can choose how sensitive the neurons in the neural network will react to information found in the training data in each iteration.<br>
When the learning rate is too high, a lot of information is cut out and this will lead to poor performance. 
When the learning rate is too small, the neural network will take very long to find a result.</p>
<p><a href="https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10">read more</a></p>
<h3 id="LR-Finder">LR Finder<a class="anchor-link" href="#LR-Finder"> </a></h3><p>The learning rate finder is an automated approach to find an optimal learning rate for your use case. It approximates a value that can be a good compromise between resulting performance of the model on the one hand and training duration on the other.</p>
<p><a href="https://towardsdatascience.com/the-learning-rate-finder-6618dfcb2025">read more</a></p>
<h3 id="Number-of-epochs">Number of epochs<a class="anchor-link" href="#Number-of-epochs"> </a></h3><p>With the number of epochs we can set how often the training data is shown to the neural network.</p>
<p><a href="https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">read more</a></p>
<h3 id="Batch-size">Batch size<a class="anchor-link" href="#Batch-size"> </a></h3><p>With the batch size we can set how many samples from our training data are fed through the neural network in one iteration.</p>
<p><a href="https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">read more</a></p>
<h3 id="Ensemble-Training">Ensemble Training<a class="anchor-link" href="#Ensemble-Training"> </a></h3><p>Ensemble training combines multiple models to optimize the result.
The result is represented as a weighted average.</p>
<p><a href="https://arxiv.org/abs/2104.02395">read more</a></p>
<h3 id="TTA-test-time-augmentation">TTA test time augmentation<a class="anchor-link" href="#TTA-test-time-augmentation"> </a></h3><p>TTA randomly modifies the images from the sample data after they were fed through the neural network and repeats the training. The goal is to enable the neural network to extract more general features from the images in the sample data. Typical modifications are alterations in zoom, orientation of the images and flips.</p>
<p><a href="https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d">read more</a></p>
<h3 id="STAPLE-Algorithm">STAPLE Algorithm<a class="anchor-link" href="#STAPLE-Algorithm"> </a></h3><p>The STAPLE algorithm is used to validate the segmentation of an image. Either from an expert or a model used for a neural network. STAPLE stands for simultaneous truth and performance level estimation and works by comparing multiple segmentation jobs done by different experts or models for the same image. Further the algorithm tries to address deviations in segmentation skills or biases between experts. This allows the better segmentation to have more influence on the overall result.</p>
<p><a href="https://www.researchgate.net/publication/8458086_Simultaneous_Truth_and_Performance_Level_Estimation_STAPLE_An_Algorithm_for_the_Validation_of_Image_Segmentation">read more</a></p>
<h3 id="Majority-Voting-Algorithm">Majority Voting Algorithm<a class="anchor-link" href="#Majority-Voting-Algorithm"> </a></h3><p>The algorithm looks for a majority in the segmented data and uses it as the single truth to evaluate the segmentation performance of the neural network. The majority in this case describes similarities that can be found in most expert segmentations. To find the majorities, the algorithm will not weigh in any qualitative aspects. Therefore this can lead to biased results, when the expertâ€™s segmentation skills do vary.</p>
<p><a href="https://www.geeksforgeeks.org/boyer-moore-majority-voting-algorithm/">read more</a></p>
<h3 id="Model:">Model:<a class="anchor-link" href="#Model:"> </a></h3><p>The model represents the final settings of the neural network when the training process is finished. These settings include the weights of every single neuron in the neural network and can be exported as a file to be used for future object recognition tasks. To achieve good results with a pre-trained model, the images should contain similar objects and structures to those used to train the model.</p>
<p><a href="https://towardsdatascience.com/building-a-deep-learning-model-using-keras-1548ca149d37">read more</a></p>

</div>
</div>
</div>
</div>
 

