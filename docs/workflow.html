---

title: Workflow


keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/workflow.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/workflow.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-Google-Colab:">Using Google Colab:<a class="anchor-link" href="#Using-Google-Colab:"> </a></h2><p>{% include note.html content='If not already done, we recommend you to read the <a href="before_you_get_started.html">Before you get started guide</a> first.  ' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="For-using-deepflash2-in-Google-Colab-follow-this-link">For using deepflash2 in Google Colab follow this link<a class="anchor-link" href="#For-using-deepflash2-in-Google-Colab-follow-this-link"> </a></h3><p>(<a href="https://colab.research.google.com/github/matjesg/deepflash2/blob/master/nbs/deepflash2.ipynb">https://colab.research.google.com/github/matjesg/deepflash2/blob/master/nbs/deepflash2.ipynb</a>)</p>
<h3 id="1.Video">1.Video<a class="anchor-link" href="#1.Video"> </a></h3><p>The whole workflow is also explained in this video. <a href="https://www.youtube.com/watch?v=rEZzoDEq_-Y">click here</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-Setup-Environment">2. Setup Environment<a class="anchor-link" href="#2.-Setup-Environment"> </a></h3><p>At first you must allow google colab to run the notebook from GitHub by accepting the prompt.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-Connect-your-google-drive">3. Connect your google drive<a class="anchor-link" href="#3.-Connect-your-google-drive"> </a></h3><p>It is recommended to connect your runtime to google drive.
{% include note.html content='Make sure that the google drive account you use with google colab is the same as the one you connect to the runtime.' %}
You can allow it with ‘y’ for yes or deny it with ‘n’ for no.</p>
<p>Go to the Url that is presented to you in the “Set up environment cell”.
There you can choose your google drive account to connect to google colab.</p>
<p>After you have successfully connected the accounts, google will present you a one time authorization code. Copy this code and enter it in the according field in the “Set up environment cell” and continue by pressing the enter key.
{% include note.html content='The authentication key will only work with this runtime. When you close google colab you have to request a new code as described.   ' %}{% include note.html content='You can <strong>reset the runtime</strong> when DeepFlash2 does not respond anymore.<br>' %}Click on runtime in the left upper toolbar and select <strong>factory reset runtime</strong>.<br>
Then you should reload the page and start again. 
<img src="/deepflash2/./media/screen_captures/GUI_reset_runtime.gif" alt="reset runtime"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.-Start-deepflash2-UI">4. Start deepflash2 UI<a class="anchor-link" href="#4.-Start-deepflash2-UI"> </a></h3><p>{% include note.html content='You have to create a Folder Structure as described <a href="before_you_get_started.ipynb">here</a>, before starting the program.' %}
When you run this cell, the UI opens. At first click “Select Project Folder”. 
This unfolds your google drive main directory.</p>
<p>There you can browse through the folders and select the correct folders.
After that hit Save. Now the selected folder is connected to deepFlash2.</p>
<p>The select folder tab will change to the name of the selected folder.
If you want to change the folder, click this button again.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="5.-GT-Estimation">5. GT Estimation<a class="anchor-link" href="#5.-GT-Estimation"> </a></h3><h4 id="5.1.-Expert-Annotations">5.1. Expert Annotations<a class="anchor-link" href="#5.1.-Expert-Annotations"> </a></h4><p>You can estimate the ground truth by selecting images that are segmented beforehand by different experts. We recommend at least twelve different images from three different experts. After you have selected the desired data, you can press Load Data.</p>
<h4 id="5.2.-Ground-Truth-Estimation:">5.2. Ground Truth Estimation:<a class="anchor-link" href="#5.2.-Ground-Truth-Estimation:"> </a></h4><p>When you have uploaded the images you can start the ground truth estimation by selecting one of the presented algorithms.
At the time of writing you can select between STAPLE and Majority Voting.</p>
<p>We recommend the STAPLE Algorithm when:</p>
<ul>
<li>the experience of experts that have annotated the images vary or is unknown</li>
<li>you need more precise results when compared with the Majority Voting Algorithm</li>
</ul>
<p>We recommend the Majority Voting Algorithm when:</p>
<ul>
<li>Use this algorithm if you can be sure that the expert annotations have no repeated errors.</li>
</ul>
<p>When the estimation is finished you can download the ground truth images for further use in training. If you proceed with training, deepFlash2 will automatically select them for you.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="6.-Training-the-model">6. Training the model<a class="anchor-link" href="#6.-Training-the-model"> </a></h3><p>In this step you will create a model that you can use to automatically annotate new images.</p>
<h4 id="6.1-Data">6.1 Data<a class="anchor-link" href="#6.1-Data"> </a></h4><p>First, you have to provide training images. These should be unsegmented and contain the objects you want the neural network to find.
Second, you have to offer segmentation masks you have to create beforehand.
DeepFlash2 automatically recognizes the number of masks you have provided.<br>
Third, you have to select a number of classes. The number of classes to choose depends on the characteristics of the segmentation. 
E.g., two for binary segmentation (foreground and background class).
Fourth, you can provide instance labels. This step is optional.</p>
<h4 id="6.2-Ensemble-Training">6.2 Ensemble Training<a class="anchor-link" href="#6.2-Ensemble-Training"> </a></h4><p>{% include note.html content='We recommend that you use 70% of your image data for model training and reserve 30% for later validation. DeepFlash2 will automatically split the images you provide for you.' %}
You can use the Ensemble training to optimize the results.
First choose a number of models within an ensemble. 
Depending on the data, ensembles should at least have three models.
If you are experimenting with custom train settings, try only one model first.</p>
<h4 id="6.3-Validation">6.3 Validation<a class="anchor-link" href="#6.3-Validation"> </a></h4><p>{% include note.html content='We recommend that you reserve 30% of your image data for validation.' %}
Here you can validate the performance of the model you have trained before with unsegmented images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="7.-Prediction">7. Prediction<a class="anchor-link" href="#7.-Prediction"> </a></h3><p>In this section you can use a model to segment new images and evaluate the
precision.</p>
<h4 id="7.1-Data-and-Ensemble">7.1 Data and Ensemble<a class="anchor-link" href="#7.1-Data-and-Ensemble"> </a></h4><p>First you have to upload the images you want the model to work on.
Second you have to select the model or model ensemble  you want to apply on the images. If you have used deepFlash2 to train the model, it will automatically select the model/s in the</p>
<h4 id="7.2-Prediction-and-Quality-Control">7.2 Prediction and Quality Control<a class="anchor-link" href="#7.2-Prediction-and-Quality-Control"> </a></h4><p>Here you can run the prediction and download the results.
You can enable test-time augmentation for prediction (more reliable and accurate, but slow).</p>

</div>
</div>
</div>
</div>
 

