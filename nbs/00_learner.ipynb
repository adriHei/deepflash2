{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp learner\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learner\n",
    "\n",
    "> Implements functions necessary to build an  `EnsembleLearner` suitable for bioimgage segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import shutil, gc, joblib, json, zarr, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.basics import patch, GetAttr\n",
    "from fastcore.foundation import add_docs, L\n",
    "from fastai import optimizer\n",
    "from fastai.torch_core import TensorImage\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.transforms import get_image_files, get_files, Normalize\n",
    "from fastai.vision.augment import Brightness, Contrast, Saturation\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "\n",
    "from deepflash2.metrics import Dice_f1, Iou\n",
    "from deepflash2.losses import WeightedSoftmaxCrossEntropy,load_kornia_loss\n",
    "from deepflash2.callbacks import ElasticDeformCallback\n",
    "from deepflash2.models import get_default_shapes, load_smp_model\n",
    "from deepflash2.data import TileDataset, RandomTileDataset, _read_img, _read_msk\n",
    "from deepflash2.utils import iou, plot_results, get_label_fn, calc_iterations, save_mask, save_unc, compose_albumentations\n",
    "from deepflash2.utils import compose_albumentations as _compose_albumentations\n",
    "import deepflash2.tta as tta\n",
    "from deepflash2.transforms import WeightTransform, calculate_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"Config class for settings.\"\n",
    "\n",
    "    # Project\n",
    "    proj_dir:str = 'deepflash2'\n",
    "\n",
    "    # GT Estimation Settings\n",
    "    staple_thres:float = 0.5\n",
    "    staple_fval:int= 1\n",
    "    mv_undec:int = 0\n",
    "\n",
    "    # Train General Settings\n",
    "    n:int = 4\n",
    "    max_splits:int=5\n",
    "    repo:str = 'matjesg/deepflash2'\n",
    "    arch:str = 'unext50_deepflash2'\n",
    "    pretrained:str = None\n",
    "    random_state:int = 42\n",
    "        \n",
    "    # Pytorch Segmentation Model Settings\n",
    "    encoder_name:str = 'efficientnet-b4'\n",
    "    encoder_weights:str = 'imagenet'\n",
    "\n",
    "    # Train Data Settings\n",
    "    c:int = 2\n",
    "    il:bool = False\n",
    "\n",
    "    # Train Settings\n",
    "    lr:float = 0.001\n",
    "    bs:int = 4\n",
    "    wd:float = 0.001\n",
    "    mpt:bool = False\n",
    "    optim:str = 'ranger'\n",
    "    loss:str = 'WeightedSoftmaxCrossEntropy'\n",
    "    n_iter:int = 1000\n",
    "\n",
    "    # Validation and Prediction Settings\n",
    "    tta:bool = True\n",
    "    border_padding_factor:float = 0.25\n",
    "    shift:float = 0.5\n",
    "\n",
    "    # Train Data Augmentation\n",
    "    CLAHE_clip_limit:float = 0.0\n",
    "    brightness_limit:float = 0.0\n",
    "    contrast_limit:float = 0.0\n",
    "    zoom_sigma:float = 0.0\n",
    "    flip:bool = True\n",
    "    rot:int = 360\n",
    "    deformation_grid:int = 150\n",
    "    deformation_magnitude:int = 10\n",
    "        \n",
    "    # Loss Settings Kornia\n",
    "    loss_alpha:float = 0.5 # Twerksky/Focal loss\n",
    "    loss_beta:float = 0.5 # Twerksy Loss\n",
    "    loss_gamma:float = 2.0 # Focal loss\n",
    "    \n",
    "    # Loss Mask Weights (WeightedSoftmaxCrossEntropy)\n",
    "    bwf:int = 25\n",
    "    bws:int = 10\n",
    "    fds:int = 10\n",
    "    fbr:float = 0.5\n",
    "\n",
    "    # Pred Settings\n",
    "    pred_tta:bool = True\n",
    "\n",
    "    # OOD Settings\n",
    "    kernel:str = 'rbf'\n",
    "    nu:float = 0.01\n",
    "    gamma:float = 0.01\n",
    "    energy_ks:int = 20\n",
    "\n",
    "    # Folder Structure\n",
    "    gt_dir:str = 'GT_Estimation'\n",
    "    train_dir:str = 'Training'\n",
    "    pred_dir:str = 'Prediction'\n",
    "    ens_dir:str = 'ensemble'\n",
    "    val_dir:str = 'valid'\n",
    "\n",
    "    @property\n",
    "    def mw_kwargs(self):\n",
    "        kwargs = ['bwf', 'bws', 'fds', 'fbr']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "    \n",
    "    @property\n",
    "    def albumentation_kwargs(self):\n",
    "        kwargs = ['CLAHE_clip_limit', 'brightness_limit', 'contrast_limit']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "\n",
    "    @property\n",
    "    def svm_kwargs(self):\n",
    "        svm_vars = ['kernel', 'nu', 'gamma']\n",
    "        return dict(filter(lambda x: x[0] in svm_vars, self.__dict__.items()))\n",
    "\n",
    "    def save(self, path):\n",
    "        'Save configuration to path'\n",
    "        path = Path(path)\n",
    "        with open(path.with_suffix('.json'), 'w') as config_file:\n",
    "            json.dump(asdict(self), config_file)\n",
    "        print(f'Saved current configuration to {path}.json')\n",
    "\n",
    "    def load(self, path):\n",
    "        'Load configuration from path'\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with open(path) as config_file: c = json.load(config_file)\n",
    "            if not Path(c['proj_dir']).is_dir(): c['proj_dir']='deepflash2'\n",
    "            for k,v in c.items(): setattr(self, k, v)\n",
    "            print(f'Successsfully loaded configuration from {path}')\n",
    "        except:\n",
    "            print('Error! Select valid config file (.json)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current configuration to test_config.json\n",
      "Successsfully loaded configuration from test_config.json\n"
     ]
    }
   ],
   "source": [
    "t1 = Config(n=3)\n",
    "t1.save('test_config')\n",
    "t2 = Config()\n",
    "t2.load('test_config.json')\n",
    "test_eq(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_optim_dict = {\n",
    "    'ranger' : optimizer.ranger,\n",
    "    'Adam' : optimizer.Adam,\n",
    "    'RAdam' : optimizer.RAdam,\n",
    "    'QHAdam' :optimizer.QHAdam,\n",
    "    'Larc' : optimizer.Larc,\n",
    "    'Lamb' : optimizer.Lamb,\n",
    "    'SGD' : optimizer.SGD,\n",
    "    'RMSProp' : optimizer.RMSProp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches for the `fastai` Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def apply_dropout(self:Learner):\n",
    "    \"If a module contains 'dropout', it will be switched to .train() mode.\"\n",
    "    for m in self.model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def energy_max(e, ks=20, dim=None):\n",
    "    e = torch.as_tensor(e).resize_((1,1,*e.shape))\n",
    "    e = F.avg_pool2d(e, ks)\n",
    "    return torch.max(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.random.randn(1024,1024)\n",
    "test_close(energy_max(e, ks=100),0, eps=1e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from https://github.com/MIC-DKFZ/nnUNet/blob/2fade8f32607220f8598544f0d5b5e5fa73768e5/nnunet/network_architecture/neural_network.py#L250\n",
    "def _get_gaussian(patch_size, sigma_scale=1. / 8) -> np.ndarray:\n",
    "    tmp = np.zeros(patch_size)\n",
    "    center_coords = [i // 2 for i in patch_size]\n",
    "    sigmas = [i * sigma_scale for i in patch_size]\n",
    "    tmp[tuple(center_coords)] = 1\n",
    "    gaussian_importance_map = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)\n",
    "    gaussian_importance_map = gaussian_importance_map / np.max(gaussian_importance_map) * 1\n",
    "    gaussian_importance_map = gaussian_importance_map.astype(np.float32)\n",
    "\n",
    "    # gaussian_importance_map cannot be 0, otherwise we may end up with nans!\n",
    "    gaussian_importance_map[gaussian_importance_map == 0] = np.min(\n",
    "        gaussian_importance_map[gaussian_importance_map != 0])\n",
    "\n",
    "    return gaussian_importance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = _get_gaussian((512,512))\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tiles(self:Learner, ds_idx=1, dl=None, path=None, mc_dropout=False, n_times=1, use_tta=True, verbose=0,\n",
    "                       tta_merge='mean', tta_tfms=None, uncertainty_estimates=True, energy_T=1, merge='gauss'):\n",
    "    \"Make predictions and reconstruct tiles, optional with dropout and/or tta applied.\"\n",
    "\n",
    "    if dl is None: dl = self.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
    "    assert isinstance(dl.dataset, TileDataset), \"Provide dataloader containing a TileDataset\"\n",
    "    if use_tta: \n",
    "        tfms = tta_tfms or [tta.HorizontalFlip(), tta.VerticalFlip()] #tta.Rotate90(angles=[90,180,270])\n",
    "        if verbose>0: print('Using Test-Time Augmentation with:', tfms)\n",
    "    else: tfms=[]\n",
    "        \n",
    "    if merge == 'gauss':\n",
    "        merge_map = _get_gaussian(dl.output_shape)\n",
    "    elif merge == 'mean':\n",
    "        merge_map = np.ones(dl.output_shape)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Use 'gauss' or 'mean' for merge function.\")\n",
    "    mm = torch.from_numpy(merge_map)\n",
    "\n",
    "    self.model.eval()\n",
    "    if mc_dropout: self.apply_dropout()\n",
    "  \n",
    "    store = str(path) if path else zarr.storage.TempStore()\n",
    "    root = zarr.group(store=store, overwrite=True)\n",
    "    g_smx, g_seg, g_std, g_eng, g_wgt  = root.create_groups('smx', 'seg', 'std', 'energy', 'wgt')\n",
    "    active = ['smx', 'std', 'eng', 'wgt'] if uncertainty_estimates else ['smx', 'wgt']\n",
    "    \n",
    "    i = 0\n",
    "    last_file = None\n",
    "    if verbose>0: print(f'Starting prediction with overlapping tiles (shift factor {dl.shift})...')\n",
    "    for data in progress_bar(dl, leave=False):\n",
    "        if isinstance(data, TensorImage): images = data\n",
    "        else: images, _, _ = data\n",
    "        mm = mm.to(images)\n",
    "        m_smx = tta.Merger()\n",
    "        m_energy = tta.Merger()\n",
    "        out_list_smx = []\n",
    "        for t in tta.Compose(tfms):\n",
    "            for _ in range(n_times):\n",
    "                aug_images = t.augment_image(images)\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(aug_images)\n",
    "                out = t.deaugment_mask(out)\n",
    "                if dl.padding[0]!= images.shape[-1]-out.shape[-1]: \n",
    "                    padding = ((images.shape[-1]-out.shape[-1]-dl.padding[0])//2,)*4\n",
    "                    out = F.pad(out, padding)  \n",
    "                if dl.c==1:\n",
    "                    out_act = torch.sigmoid(out)\n",
    "                    out_act = torch.cat([(1-out_act), out_act], dim=1)\n",
    "                else:\n",
    "                    out_act = F.softmax(out, dim=1)\n",
    "                m_smx.append(out_act)\n",
    "                if uncertainty_estimates:\n",
    "                    e = (energy_T*torch.logsumexp(out/energy_T, dim=1)) #negative energy score\n",
    "                    m_energy.append(e)\n",
    "        \n",
    "        ll = []\n",
    "        batch_smx = m_smx.result()*mm.view(1,1,*mm.shape)\n",
    "        ll.append([x for x in batch_smx.permute(0,2,3,1).cpu().numpy()])\n",
    "        \n",
    "        if uncertainty_estimates:\n",
    "            batch_std = torch.mean(m_smx.result('std'), 1)*mm.view(1,*mm.shape)\n",
    "            ll.append([x for x in batch_std.cpu().numpy()])\n",
    "            \n",
    "            batch_energy =  m_energy.result()*mm.view(1,*mm.shape)\n",
    "            ll.append([x for x in batch_energy.cpu().numpy()])\n",
    "        \n",
    "        for j, preds in enumerate(zip(*ll)):\n",
    "            if len(preds)==3: smx,std,eng = preds\n",
    "            else: smx = preds[0]\n",
    "            idx = i+j\n",
    "            f = dl.files[dl.image_indices[idx]]\n",
    "            outShape = dl.image_shapes[idx]\n",
    "            outSlice = dl.out_slices[idx]\n",
    "            inSlice = dl.in_slices[idx]\n",
    "            if last_file!=f: \n",
    "                z_smx = g_smx.zeros(f.name, shape=(*outShape, max(2, dl.c)), dtype='float32')\n",
    "                z_std = g_std.zeros(f.name, shape=outShape, dtype='float32')\n",
    "                z_eng = g_eng.zeros(f.name, shape=outShape, dtype='float32')\n",
    "                z_wgt = g_wgt.zeros(f.name, shape=outShape, dtype='float32')\n",
    "                last_file = f\n",
    "            z_smx[outSlice] += smx[inSlice]\n",
    "            z_wgt[outSlice] += merge_map[inSlice]\n",
    "            if uncertainty_estimates:\n",
    "                z_std[outSlice] += std[inSlice]\n",
    "                z_eng[outSlice] += eng[inSlice]\n",
    "        i += dl.bs\n",
    "        \n",
    "    if verbose>0: print(f'Merging predictions with {merge} weights...')\n",
    "    for k in progress_bar(g_smx, leave=False):\n",
    "        wgt = g_wgt[k][:]\n",
    "        smx_norm = g_smx[k][:] / wgt[..., np.newaxis]\n",
    "        g_smx[k] = smx_norm\n",
    "        g_seg[k] = np.argmax(smx_norm, axis=-1)\n",
    "        if uncertainty_estimates:\n",
    "            g_std[k] /= wgt\n",
    "            g_eng[k] /= wgt\n",
    "            \n",
    "    return g_smx, g_seg, g_std, g_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self, channels=2, padding=None):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.channels = channels\n",
    "    def forward(self, inp):\n",
    "        if self.padding:\n",
    "            inp = F.pad(inp, (-self.padding//2,)*4)\n",
    "        if self.channels==1: return inp\n",
    "        else: return torch.cat([(inp*-1), inp], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Test-Time Augmentation with: [<deepflash2.tta.HorizontalFlip object at 0x7f2679f9a1f0>, <deepflash2.tta.VerticalFlip object at 0x7f2591154cd0>]\n",
      "Starting prediction with overlapping tiles (shift factor {dl.shift})...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging predictions with gauss weights...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (np.random.rand(1024,1024)>0.5).astype('uint8')\n",
    "imageio.imsave('tst_msk.png', mask)\n",
    "files = [Path('tst_msk.png')]\n",
    "model = TestModel(padding=50)\n",
    "ds_kwargs = {'tile_shape':(512,512), 'padding':(76,76), 'scale':1, 'shift':0.8}\n",
    "ds = TileDataset(files, **ds_kwargs)\n",
    "dls = DataLoaders.from_dsets(ds, batch_size=4, shuffle=False, drop_last=False)\n",
    "learn = Learner(dls, model, loss_func='')\n",
    "g_smx, g_seg, g_std, g_eng = learn.predict_tiles(dl=dls.train, merge='gauss', verbose=1)\n",
    "out = g_seg[files[0]][:]\n",
    "test_eq(mask, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TestModel(padding=50, channels=1)\n",
    "ds_kwargs = {'tile_shape':(256,256), 'padding':(76,76), 'scale':1, 'shift':1, 'n_classes':1}\n",
    "ds = TileDataset(files, **ds_kwargs)\n",
    "dls = DataLoaders.from_dsets(ds, batch_size=4, shuffle=False, drop_last=False)\n",
    "learn = Learner(dls, model, loss_func='')\n",
    "g_smx, g_seg, g_std, g_eng = learn.predict_tiles(dl=dls.train)\n",
    "out = g_seg[files[0]][:]\n",
    "test_eq(mask, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleLearner(GetAttr):\n",
    "    _default = 'config' \n",
    "    def __init__(self, image_dir='images', mask_dir=None, config=None, path=None, ensemble_dir=None, item_tfms=None,\n",
    "                 label_fn=None, metrics=None, cbs=None, ds_kwargs={}, dl_kwargs={}, model_kwargs={}, stats=None, files=None):\n",
    "\n",
    "        self.config = config or Config()\n",
    "        self.stats = stats \n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.add_ds_kwargs = ds_kwargs\n",
    "        self.item_tfms = item_tfms\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        self.metrics = metrics or [Iou(), Dice_f1()]\n",
    "        self.loss_fn = self.get_loss()\n",
    "        self.cbs = cbs or [SaveModelCallback(monitor='iou'), ElasticDeformCallback] #ShowGraphCallback\n",
    "        self.ensemble_dir = ensemble_dir or self.path/'ensemble'    \n",
    "        \n",
    "        self.files = L(files) or get_image_files(self.path/image_dir, recurse=False)\n",
    "        assert len(self.files)>0, f'Found {len(self.files)} images in \"{image_dir}\". Please check your images and image folder'\n",
    "        if any([mask_dir, label_fn]):\n",
    "            if label_fn: self.label_fn = label_fn\n",
    "            else: self.label_fn = get_label_fn(self.files[0], self.path/mask_dir)\n",
    "            #Check if corresponding masks exist\n",
    "            mask_check = [self.label_fn(x).exists() for x in self.files]\n",
    "            chk_str = f'Found {len(self.files)} images in \"{image_dir}\" and {sum(mask_check)} masks in \"{mask_dir}\".'\n",
    "            assert len(self.files)==sum(mask_check) and len(self.files)>0, f'Please check your images and masks (and folders). {chk_str}'\n",
    "            print(chk_str)\n",
    "                  \n",
    "        else:\n",
    "            self.label_fn = label_fn\n",
    "        self.n_splits=min(len(self.files), self.max_splits)\n",
    "          \n",
    "        self.models = {}\n",
    "        self.recorder = {}\n",
    "        self._set_splits()\n",
    "        self.ds = RandomTileDataset(self.files, label_fn=self.label_fn, **self.mw_kwargs, **self.ds_kwargs)\n",
    "        self.in_channels = self.ds.get_data(max_n=1)[0].shape[-1]\n",
    "        self.df_val, self.df_ens, self.df_model, self.ood = None,None,None,None\n",
    "    \n",
    "    @property\n",
    "    def out_size(self):\n",
    "        return self.ds_kwargs['tile_shape'][0]-self.ds_kwargs['padding'][0]\n",
    "           \n",
    "    def _set_splits(self):\n",
    "        if self.n_splits>1:\n",
    "            kf = KFold(self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.splits = {key:(self.files[idx[0]], self.files[idx[1]]) for key, idx in zip(range(1,self.n_splits+1), kf.split(self.files))}    \n",
    "        else:\n",
    "            self.splits = {1: (self.files[0], self.files[0])}\n",
    "            \n",
    "    def compose_albumentations(self, **kwargs):\n",
    "        return _compose_albumentations(**kwargs)\n",
    "    \n",
    "    @property        \n",
    "    def ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        for key, value in get_default_shapes(self.arch).items():\n",
    "            ds_kwargs.setdefault(key, value)\n",
    "        # Settings from config\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= 1.\n",
    "        ds_kwargs['border_padding_factor']= 0.\n",
    "        ds_kwargs['loss_weights'] = True if self.loss=='WeightedSoftmaxCrossEntropy' else False\n",
    "        ds_kwargs['zoom_sigma'] = self.zoom_sigma\n",
    "        ds_kwargs['flip'] = self.flip\n",
    "        ds_kwargs['deformation_grid']= (self.deformation_grid,)*2\n",
    "        ds_kwargs['deformation_magnitude'] = (self.deformation_magnitude,)*2\n",
    "        if sum(self.albumentation_kwargs.values())>0: \n",
    "            ds_kwargs['albumentation_tfms'] = self.compose_albumentations(**self.albumentation_kwargs)\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property        \n",
    "    def pred_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        for key, value in get_default_shapes(self.arch).items():\n",
    "            ds_kwargs.setdefault(key, value)\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= self.shift\n",
    "        ds_kwargs['border_padding_factor']= self.border_padding_factor\n",
    "        return ds_kwargs\n",
    "            \n",
    "            \n",
    "    def get_loss(self):\n",
    "        if self.loss == 'WeightedSoftmaxCrossEntropy': return WeightedSoftmaxCrossEntropy(axis=1)\n",
    "        if self.loss == 'CrossEntropyLoss': return CrossEntropyLossFlat(axis=1)\n",
    "        else: \n",
    "            kwargs = {'alpha':self.loss_alpha, 'beta':self.loss_beta, 'gamma':self.loss_gamma}\n",
    "            return load_kornia_loss(self.loss, **kwargs)\n",
    "            \n",
    "    def get_model(self, pretrained):\n",
    "        if self.arch in [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\", \"unet_custom\", \"unext50_deepflash2\"]:\n",
    "            model = torch.hub.load(self.repo, self.arch, pretrained=pretrained, n_classes=self.c, in_channels=self.in_channels, **self.model_kwargs)\n",
    "        else:\n",
    "            kwargs = dict(encoder_name=self.encoder_name, encoder_weights=self.encoder_weights, \n",
    "                          in_channels=self.in_channels, classes=self.c, **self.model_kwargs)\n",
    "            model = load_smp_model(self.arch, **kwargs)\n",
    "        if torch.cuda.is_available(): model.cuda()\n",
    "        return model\n",
    "    \n",
    "    def get_dls(self, files, files_val=None):\n",
    "        ds = []\n",
    "        ds.append(RandomTileDataset(files, label_fn=self.label_fn, **self.mw_kwargs, **self.ds_kwargs))\n",
    "        if files_val: \n",
    "            ds.append(TileDataset(files_val, label_fn=self.label_fn, **self.mw_kwargs,**self.ds_kwargs))\n",
    "        else:\n",
    "            ds.append(ds[0])\n",
    "        dls = DataLoaders.from_dsets(*ds, bs=self.bs, after_item=self.item_tfms, after_batch=self.get_batch_tfms(), **self.dl_kwargs)\n",
    "        if torch.cuda.is_available(): dls.cuda()\n",
    "        return dls\n",
    "        \n",
    "    def save_model(self, file, model, pickle_protocol=2):\n",
    "        state = model.state_dict()\n",
    "        state = {'model': state, 'arch':self.arch, 'stats':self.stats, 'c':self.c}\n",
    "        if self.arch in [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\", \"unet_custom\", \"unext50_deepflash2\"]:\n",
    "            state['repo']=self.repo\n",
    "        else:\n",
    "            state['encoder_name']=self.encoder_name\n",
    "        torch.save(state, file, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)\n",
    "    \n",
    "    def load_model(self, file, with_meta=True, device=None, strict=True):\n",
    "        if isinstance(device, int): device = torch.device('cuda', device)\n",
    "        elif device is None: device = 'cpu'\n",
    "        state = torch.load(file, map_location=device)\n",
    "        hasopt = 'model' in state#set(state)=={'model', 'arch', 'repo', 'stats', 'c'}\n",
    "        if hasopt:\n",
    "            model_state = state['model']\n",
    "            if with_meta:\n",
    "                for opt in state:\n",
    "                    if opt!='model': setattr(self.config, opt, state[opt])            \n",
    "        else:\n",
    "            model_state = state                \n",
    "        model = self.get_model(pretrained=None)\n",
    "        model.load_state_dict(model_state, strict=strict)\n",
    "        return model\n",
    "    \n",
    "    def get_batch_tfms(self):\n",
    "        self.stats = self.stats or self.ds.compute_stats()\n",
    "        tfms = [Normalize.from_stats(*self.stats)]\n",
    "        if isinstance(self.loss_fn, WeightedSoftmaxCrossEntropy):\n",
    "            tfms.append(WeightTransform(self.out_size, **self.mw_kwargs))\n",
    "        return tfms\n",
    "        \n",
    "    def fit(self, i, n_iter=None, lr_max=None, **kwargs):\n",
    "        n_iter = n_iter or self.n_iter\n",
    "        lr_max = lr_max or self.lr\n",
    "        name = self.ensemble_dir/f'{self.arch}_model-{i}.pth'\n",
    "        pre = None if self.pretrained=='new' else self.pretrained\n",
    "        model = self.get_model(pretrained=pre)\n",
    "        files_train, files_val = self.splits[i]\n",
    "        dls = self.get_dls(files_train, files_val)    \n",
    "        self.learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim], cbs=self.cbs)\n",
    "        self.learn.model_dir = self.ensemble_dir.parent/'.tmp'\n",
    "        if self.mpt: self.learn.to_fp16()\n",
    "        print(f'Starting training for {name.name}')\n",
    "        epochs = calc_iterations(n_iter=n_iter,ds_length=len(dls.train_ds), bs=self.bs)\n",
    "        self.learn.fit_one_cycle(epochs, lr_max)\n",
    "\n",
    "        print(f'Saving model at {name}')\n",
    "        name.parent.mkdir(exist_ok=True, parents=True)\n",
    "        self.save_model(name, self.learn.model)\n",
    "        self.models[i]=name\n",
    "        self.recorder[i]=self.learn.recorder\n",
    "        #del model\n",
    "        #gc.collect()\n",
    "        #torch.cuda.empty_cache()  \n",
    "        \n",
    "    def fit_ensemble(self, n_iter, skip=False, **kwargs):\n",
    "        for i in range(1, self.n+1):\n",
    "            if skip and (i in self.models): continue\n",
    "            self.fit(i, n_iter,  **kwargs)\n",
    "       \n",
    "    def set_n(self, n):\n",
    "        for i in range(n, len(self.models)):\n",
    "            self.models.pop(i+1, None)            \n",
    "        self.n = n\n",
    "                 \n",
    "    def predict(self, files, model_no, path=None, **kwargs):\n",
    "        model_path = self.models[model_no]\n",
    "        model = self.load_model(model_path)\n",
    "        ds = TileDataset(files, **self.pred_ds_kwargs)\n",
    "        dls = DataLoaders.from_dsets(ds, batch_size=self.bs, after_batch=self.get_batch_tfms(), shuffle=False, drop_last=False, **self.dl_kwargs)\n",
    "        if torch.cuda.is_available(): dls.cuda()\n",
    "        learn = Learner(dls, model, loss_func=self.loss_fn)\n",
    "        if self.mpt: learn.to_fp16()\n",
    "        if path: path = path/f'model_{model_no}'\n",
    "        return learn.predict_tiles(dl=dls.train, path=path, **kwargs)\n",
    "                               \n",
    "    def get_valid_results(self, model_no=None, export_dir=None, filetype='.png', **kwargs):\n",
    "        res_list = []\n",
    "        model_list = self.models if not model_no else [model_no]\n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            if self.tta:\n",
    "                unc_path = export_dir/'uncertainties'\n",
    "                unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        for i in model_list:\n",
    "            _, files_val = self.splits[i]\n",
    "            g_smx, g_seg, g_std, g_eng = self.predict(files_val, i, **kwargs)\n",
    "            chunk_store = g_smx.chunk_store.path\n",
    "            for j, f in enumerate(files_val):\n",
    "                msk = self.ds.get_data(f, mask=True)[0]\n",
    "                pred = g_seg[f.name][:]\n",
    "                m_iou = iou(msk, pred)\n",
    "                m_path = self.models[i].name\n",
    "                m_eng_max = energy_max(g_eng[f.name][:], ks=self.energy_ks)\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                        'model' :  m_path,\n",
    "                        'model_no' : i,\n",
    "                        'img_path': f,\n",
    "                        'iou': m_iou,\n",
    "                        'energy_max': m_eng_max.numpy(),\n",
    "                        'msk_path': self.label_fn(f),\n",
    "                        'pred_path': f'{chunk_store}/{g_seg.path}/{f.name}',\n",
    "                        'smx_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                        'std_path': f'{chunk_store}/{g_std.path}/{f.name}'})\n",
    "                res_list.append(df_tmp)\n",
    "                if export_dir:   \n",
    "                    save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.model}_mask', filetype)\n",
    "                    if self.tta:\n",
    "                        save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_unc', filetype)\n",
    "        self.df_val = pd.DataFrame(res_list)\n",
    "        if export_dir: \n",
    "            self.df_val.to_csv(export_dir/f'val_results.csv', index=False)\n",
    "            self.df_val.to_excel(export_dir/f'val_results.xlsx')\n",
    "        return self.df_val\n",
    "        \n",
    "    def show_valid_results(self, model_no=None, files=None, **kwargs):\n",
    "        if self.df_val is None: self.get_valid_results(**kwargs)\n",
    "        df = self.df_val\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if model_no is not None: df = df[df.model_no==model_no] \n",
    "        for _, r in df.iterrows():\n",
    "            img = self.ds.get_data(r.img_path)[0][:]\n",
    "            msk = self.ds.get_data(r.img_path, mask=True)[0]\n",
    "            pred = zarr.load(r.pred_path)\n",
    "            std = zarr.load(r.std_path)\n",
    "            _d_model = f'Model {r.model_no}'\n",
    "            if self.tta: plot_results(img, msk, pred, std, df=r, model=_d_model)  \n",
    "            else: plot_results(img, msk, pred, np.zeros_like(pred), df=r, model=_d_model)  \n",
    "          \n",
    "    def load_ensemble(self, path=None):\n",
    "        path = path or self.ensemble_dir\n",
    "        models = get_files(path, extensions='.pth', recurse=False)\n",
    "        assert len(models)>0, f'No models found in {path}'\n",
    "        self.models = {}\n",
    "        for m in models:\n",
    "            model_id = int(m.stem[-1])\n",
    "            self.models[model_id] = m\n",
    "        print(f'Found {len(self.models)} models in folder {path}')\n",
    "        print(self.models)\n",
    "        \n",
    "            \n",
    "    def ensemble_results(self, files, path=None, export_dir=None, filetype='.png', use_tta=None, **kwargs):\n",
    "        use_tta = use_tta or self.pred_tta\n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            if use_tta:\n",
    "                unc_path = export_dir/'uncertainties'\n",
    "                unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        store = str(path/'ensemble') if path else zarr.storage.TempStore()\n",
    "        root = zarr.group(store=store, overwrite=True)\n",
    "        chunk_store = root.chunk_store.path\n",
    "        g_smx, g_seg, g_std, g_eng  = root.create_groups('ens_smx', 'ens_seg', 'ens_std', 'ens_energy')\n",
    "        res_list = []\n",
    "        for f in files:\n",
    "            df_fil = self.df_models[self.df_models.file==f.name]\n",
    "            assert len(df_fil)==len(self.models), \"Predictions and models to not match.\"\n",
    "            m_smx, m_std, m_eng = tta.Merger(), tta.Merger(), tta.Merger()\n",
    "            for idx, r in df_fil.iterrows():\n",
    "                m_smx.append(zarr.load(r.smx_path))\n",
    "                m_std.append(zarr.load(r.std_path))\n",
    "                m_eng.append(zarr.load(r.eng_path))\n",
    "            smx = m_smx.result().numpy()\n",
    "            g_smx[f.name] = smx\n",
    "            g_seg[f.name] = np.argmax(smx, axis=-1)\n",
    "            g_std[f.name] = m_std.result().numpy()\n",
    "            eng = m_eng.result()\n",
    "            g_eng[f.name] = eng.numpy()\n",
    "            m_eng_max = energy_max(eng, ks=self.energy_ks).numpy()\n",
    "            df_tmp = pd.Series({'file' : f.name,\n",
    "                                'model' :  f'{self.arch}_ensemble',\n",
    "                                'energy_max': m_eng_max,\n",
    "                                'img_path': f,\n",
    "                                'pred_path': f'{chunk_store}/{g_seg.path}/{f.name}',\n",
    "                                'smx_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                                'std_path': f'{chunk_store}/{g_std.path}/{f.name}',\n",
    "                                'eng_path': f'{chunk_store}/{g_eng.path}/{f.name}'})\n",
    "            res_list.append(df_tmp)\n",
    "            if export_dir:   \n",
    "                save_mask(g_seg[f.name][:], pred_path/f'{df_tmp.file}_{df_tmp.model}_mask', filetype)\n",
    "                if use_tta:\n",
    "                    save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_unc', filetype)\n",
    "        return pd.DataFrame(res_list)\n",
    "                            \n",
    "    def get_ensemble_results(self, new_files, export_dir=None, filetype='.png', **kwargs):   \n",
    "        res_list = []\n",
    "        for i in self.models:\n",
    "            g_smx, g_seg, g_std, g_eng = self.predict(new_files, i, **kwargs)\n",
    "            chunk_store = g_smx.chunk_store.path\n",
    "            for j, f in enumerate(new_files):\n",
    "                m_path = self.models[i].name\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                                    'model_no': i, \n",
    "                                    'model' :  m_path,\n",
    "                                    'img_path': f,\n",
    "                                    'pred_path': f'{chunk_store}/{g_seg.path}/{f.name}',\n",
    "                                    'smx_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                                    'std_path': f'{chunk_store}/{g_std.path}/{f.name}',\n",
    "                                    'eng_path': f'{chunk_store}/{g_eng.path}/{f.name}'})\n",
    "                res_list.append(df_tmp)\n",
    "        self.df_models = pd.DataFrame(res_list)\n",
    "        self.df_ens  = self.ensemble_results(new_files, export_dir=export_dir, filetype=filetype, **kwargs)\n",
    "        return self.df_ens\n",
    "    \n",
    "    def score_ensemble_results(self, mask_dir=None, label_fn=None):\n",
    "        if not label_fn:\n",
    "            label_fn = get_label_fn(self.df_ens.img_path[0], self.path/mask_dir)\n",
    "        for idx, r in self.df_ens.iterrows():\n",
    "            msk_path = self.label_fn(r.img_path)\n",
    "            msk = _read_msk(msk_path)\n",
    "            self.df_ens.loc[idx, 'msk_path'] = msk_path\n",
    "            pred = zarr.load(r.pred_path)\n",
    "            self.df_ens.loc[idx, 'iou'] = iou(msk, pred)\n",
    "        return self.df_ens\n",
    "    \n",
    "    def show_ensemble_results(self, files=None, model_no=None, unc=True, unc_metric=None):\n",
    "        if self.df_ens is None: assert print(\"Please run `get_ensemble_results` first.\")\n",
    "        if model_no is None: df = self.df_ens\n",
    "        else: df = self.df_models[df_models.model_no==model_no]\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(_read_img(r.img_path)[:])\n",
    "            if 'iou' in r.index: \n",
    "                imgs.append(_read_msk(r.msk_path))\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(zarr.load(r.pred_path))\n",
    "            if unc: imgs.append(zarr.load(r.std_path))\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, unc_metric=unc_metric) \n",
    "                \n",
    "    def lr_find(self, files=None, **kwargs):\n",
    "        files = files or self.files\n",
    "        dls = self.get_dls(files)\n",
    "        pre = None if self.pretrained=='new' else self.pretrained\n",
    "        model = self.get_model(pretrained=pre)\n",
    "        learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim])\n",
    "        if self.mpt: learn.to_fp16()\n",
    "        sug_lrs = learn.lr_find(**kwargs)\n",
    "        return sug_lrs, learn.recorder  \n",
    "    \n",
    "    def show_mask_weights(self, files, figsize=(12,12), **kwargs):\n",
    "        masks = [self.label_fn(Path(f)) for f in files]\n",
    "        for m in masks:\n",
    "            print(self.mw_kwargs)\n",
    "            print(f'Calculating weights. Please wait...')\n",
    "            msk = _read_msk(m)\n",
    "            _, w, _ = calculate_weights(msk, n_dims=self.c, **self.mw_kwargs)\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize, **kwargs)\n",
    "            axes[0].imshow(msk)\n",
    "            axes[0].set_axis_off()\n",
    "            axes[0].set_title(f'Mask {m.name}')\n",
    "            axes[1].imshow(w)\n",
    "            axes[1].set_axis_off()\n",
    "            axes[1].set_title('Weights')\n",
    "            plt.show()\n",
    "    \n",
    "    def ood_train(self, features=['energy_max'], **kwargs):\n",
    "        self.ood = Pipeline([('scaler', StandardScaler()), ('svm',svm.OneClassSVM(**kwargs))])\n",
    "        self.ood.fit(self.df_ens[features])     \n",
    "        \n",
    "    def ood_score(self, features=['energy_max']):\n",
    "        self.df_ens['ood_score'] = self.ood.score_samples(self.df_ens[features])\n",
    "    \n",
    "    def ood_save(self, path):\n",
    "        path = Path(path)\n",
    "        joblib.dump(self.ood, path.with_suffix('.pkl'))\n",
    "        print(f'Saved OOD model to {path}.pkl')\n",
    "    \n",
    "    def ood_load(self, path):\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            self.ood = joblib.load(path)\n",
    "            print(f'Successsfully loaded OOD Model from {path}')\n",
    "        except: \n",
    "            print('Error! Select valid joblib file (.pkl)') \n",
    "    \n",
    "    def clear_tmp(self):\n",
    "        try: \n",
    "            shutil.rmtree('/tmp/*', ignore_errors=True)\n",
    "            shutil.rmtree(self.path/'.tmp')\n",
    "            print(f'Deleted temporary files from {self.path/\".tmp\"}')\n",
    "        except: print(f'No temporary files to delete at {self.path/\".tmp\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "add_docs(EnsembleLearner, \"Meta class to train and predict model ensembles with `n` models\",\n",
    "         save_model= \"Save `model` to `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         load_model=\"Load `model` from `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         fit=\"Fit model number `i`\",\n",
    "         fit_ensemble=\"Fit `i` models and `skip` existing\",\n",
    "         predict=\"Predict `files` with model at `model_path`\",\n",
    "         get_valid_results=\"Validate models on validation data and save results\",\n",
    "         show_valid_results=\"Plot results of all or `file` validation images\",\n",
    "         ensemble_results=\"Merge single model results\",\n",
    "         get_ensemble_results=\"Get models and ensemble results\", \n",
    "         score_ensemble_results=\"Compare ensemble results (Intersection over the Union) to given segmentation masks.\",\n",
    "         show_ensemble_results=\"Show result of ensemble or `model_no`\",\n",
    "         load_ensemble=\"Get models saved at `path`\",\n",
    "         compose_albumentations=\"Helper function to compose albumentations augmentations\",\n",
    "         get_dls=\"Create datasets and dataloaders from files\",\n",
    "         get_model=\"Get model architecture\",\n",
    "         get_loss=\"Get loss function from loss name (config)\",\n",
    "         get_batch_tfms=\"Get transform performed on batch level\",\n",
    "         set_n=\"Change to `n` models per ensemble\",\n",
    "         lr_find=\"Wrapper for learning rate finder\",\n",
    "         show_mask_weights='Plot fn for masks and weights',\n",
    "         ood_train=\"Train SVM for OOD Detection\",\n",
    "         ood_score=\"Get OOD score\",\n",
    "         ood_save='Save OOD model to path',\n",
    "         ood_load='Load OOD model from path',\n",
    "         clear_tmp=\"Clear directory with temporary files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"EnsembleLearner\" class=\"doc_header\"><code>class</code> <code>EnsembleLearner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>EnsembleLearner</code>(**`image_dir`**=*`'images'`*, **`mask_dir`**=*`None`*, **`config`**=*`None`*, **`path`**=*`None`*, **`ensemble_dir`**=*`None`*, **`item_tfms`**=*`None`*, **`label_fn`**=*`None`*, **`metrics`**=*`None`*, **`cbs`**=*`None`*, **`ds_kwargs`**=*`{}`*, **`dl_kwargs`**=*`{}`*, **`model_kwargs`**=*`{}`*, **`stats`**=*`None`*, **`files`**=*`None`*) :: `GetAttr`\n",
       "\n",
       "Meta class to train and predict model ensembles with `n` models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EnsembleLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 02a_transforms.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
