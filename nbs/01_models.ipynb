{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from fastai.layers import PixelShuffle_ICNR, ConvLayer\n",
    "from fastcore.utils import store_attr\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "from deepflash2.utils import import_package\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implementation adapted from https://github.com/jvanvugt/pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm,\n",
    "                 dropout=0., neg_slope=0.1):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        if dropout>0.:\n",
    "            block.append(nn.Dropout(p=dropout))\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "        block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "        block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm,\n",
    "                 dropout=0., neg_slope=0.1):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        up_block = []\n",
    "        if dropout>0.:\n",
    "            up_block.append(nn.Dropout(p=dropout))\n",
    "        if up_mode == 'upconv':\n",
    "            up_block.append(nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2))\n",
    "        elif up_mode == 'upsample':\n",
    "            up_block.append(nn.Upsample(mode='bilinear', scale_factor=2, align_corners=True))\n",
    "            up_block.append(nn.Conv2d(in_size, out_size, kernel_size=1))\n",
    "        if batch_norm:\n",
    "            up_block.append(nn.BatchNorm2d(out_size))\n",
    "        up_block.append(nn.LeakyReLU(negative_slope=neg_slope))\n",
    "\n",
    "        self.up = nn.Sequential(*up_block)\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UNet2D(nn.Module):\n",
    "    \"Pytorch U-Net Implementation\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        dropout = 0.,\n",
    "        neg_slope=0.,\n",
    "        up_mode='upconv',\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            if batch_norm:\n",
    "                bn = True if i>0 else False\n",
    "            else:\n",
    "                bn = False\n",
    "            if dropout>0.:\n",
    "                do = dropout if i>2 else 0.\n",
    "            else:\n",
    "                do = 0.\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding,\n",
    "                              batch_norm=bn, dropout=do,neg_slope=neg_slope)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            if batch_norm:\n",
    "                bn = True if i>0 else False\n",
    "            else:\n",
    "                bn = False\n",
    "            if dropout>0.:\n",
    "                do = dropout if i>2 else 0.\n",
    "            else:\n",
    "                do = 0.\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding,\n",
    "                            batch_norm=bn, dropout=do, neg_slope=neg_slope)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize layer weights\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Args__:\\\n",
    "`in_channels` (int): the number of input channels.\\\n",
    "`n_classes` (int): the number of output channels. \\\n",
    "`depth` (int): depth of the network.\\\n",
    "`wf` (int): number of filters in the first layer is 2^wf\n",
    "`padding` (bool): if True, apply padding such that the input shape is the same as the output. This may introduce artifacts\\\n",
    "`batch_norm` (bool): Use BatchNorm after layers with an activation function\\\n",
    "`up_mode` (str): one of 'upconv' or 'upsample'. 'upconv' will use transposed convolutions for learned upsampling. 'upsample' will use bilinear upsampling.\\\n",
    "`neg_slope`(float): Controls the angle of the negative slope for LeakyReLU. Standard ReLU if set to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_MODEL_BASE_URL = 'https://github.com/matjesg/deepflash2/releases/download/model_library/'\n",
    "def _load_pretrained(model, arch, dataset, progress=True):\n",
    "    \"Loads pretrained model weights\"\n",
    "    url = f'{_MODEL_BASE_URL}{dataset}-{arch}.pth'\n",
    "    try:\n",
    "        state_dict = torch.hub.load_state_dict_from_url(url, map_location='cpu', progress=progress)\n",
    "    except:\n",
    "        print(f\"Error: No weights available for model {arch} trained on {dataset}.\")\n",
    "        print(f\"Continuing without pretrained weights.\")\n",
    "        return\n",
    "    try:\n",
    "        if arch in [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\", \"unet_custom\"]:\n",
    "            if model.state_dict()['last.weight'].shape != state_dict['last.weight'].shape:\n",
    "                print(f\"No pretrained weights for {model.state_dict()['last.weight'].shape[0]} classes in final layer.\")\n",
    "                state_dict.pop('last.bias')\n",
    "                state_dict.pop('last.weight')\n",
    "        elif arch=='unext50_deepflash2':\n",
    "            if model.state_dict()['final_conv.0.weight'].shape != state_dict['final_conv.0.weight'].shape:\n",
    "                print(f\"No pretrained weights for {model.state_dict()['final_conv.0.weight'].shape[0]} classes in final layer.\")\n",
    "                state_dict.pop('final_conv.0.bias')\n",
    "                state_dict.pop('final_conv.0.weight')\n",
    "\n",
    "        # TODO Better handle different number of input channels\n",
    "        _ = model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded model weights trained on {dataset}.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        print(f\"Continuing without pretrained weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original U-Net architecture based on _Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unet_ronneberger2015(in_channels=1 ,n_classes=2, pretrained=None, progress=True, **kwargs):\n",
    "    \"Original U-Net architecture based on Ronnberger et al. (2015)\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes,\n",
    "                   depth=5, wf=6, padding=False, batch_norm=False,\n",
    "                   neg_slope=0., up_mode='upconv', dropout=0, **kwargs)\n",
    "    if pretrained is not None:\n",
    "        _load_pretrained(model, arch='unet_deepflash2', dataset=pretrained, progress=progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net architecture based on _Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unet_falk2019(in_channels=1 ,n_classes=2, pretrained=None, progress=True, **kwargs):\n",
    "    \"U-Net architecture based on Falk et al. (2019)\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes,\n",
    "               depth=5, wf=6, padding=False, batch_norm=False,\n",
    "               neg_slope=0.1, up_mode='upconv', dropout=0, **kwargs)\n",
    "    if pretrained is not None:\n",
    "        _load_pretrained(model, arch='unet_deepflash2', dataset=pretrained, progress=progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net model optimized for deepflash2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unet_deepflash2(in_channels=1 ,n_classes=2, pretrained=None, progress=True, dropout=.5, **kwargs):\n",
    "    \"U-Net model optimized for deepflash2\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes, dropout=dropout, \n",
    "                   depth=5, wf=6, padding=False, batch_norm=True,\n",
    "                   neg_slope=0.1, up_mode='upconv', **kwargs)\n",
    "    if pretrained is not None:\n",
    "        _load_pretrained(model, arch='unet_deepflash2', dataset=pretrained, progress=progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights trained on wue_cFOS.\n",
      "No pretrained weights for 3 classes in final layer.\n",
      "Loaded model weights trained on wue_cFOS.\n"
     ]
    }
   ],
   "source": [
    "tst = unet_deepflash2()\n",
    "tst = unet_deepflash2(pretrained='wue_cFOS')\n",
    "tst = unet_deepflash2(n_classes=3, pretrained='wue_cFOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unet_custom(in_channels=1 ,n_classes=2, pretrained=None, progress=True, **kwargs):\n",
    "    \"Customizable U-Net model. Customize via kwargs\"\n",
    "    model = UNet2D(in_channels=in_channels, n_classes=n_classes, **kwargs)\n",
    "    if pretrained:\n",
    "        print('No pretrained weights available for custom architecture.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def load_smp_model(arch, **kwargs):\n",
    "    'Load segmentation_models_pytorch model'\n",
    "    smp = import_package('segmentation_models_pytorch')\n",
    "    if arch==\"Unet\": return smp.Unet(**kwargs)\n",
    "    elif arch==\"UnetPlusPlus\": return smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":return smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": return smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": return smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": return smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": return smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": return smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": return smp.DeepLabV3Plus(**kwargs)\n",
    "    else: raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = load_smp_model(arch='DeepLabV3', in_channels=3, classes=5)\n",
    "x = torch.randn(2, 3, 512, 512)\n",
    "y = tst(x)\n",
    "test_eq(y.shape, [2, 5, 512, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Defaults "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for default input and masks shapes, depending on model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_default_shapes(arch):\n",
    "    if arch in [\"unet_deepflash2\",  \"unet_falk2019\", \"unet_ronnberger2015\", \"unet_custom\"]:\n",
    "        return {'tile_shape' : (540, 540), 'padding' : (184, 184)}\n",
    "    \n",
    "    elif arch in [\"unext50_deepflash2\"]:\n",
    "        return {'tile_shape' : (518, 518), 'padding' : (126, 126)}\n",
    "    \n",
    "    else:\n",
    "        return {'tile_shape' : (512, 512), 'padding' : (0, 0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 02a_transforms.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
